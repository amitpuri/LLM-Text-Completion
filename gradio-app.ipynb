{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc76a52-5467-4cd5-972e-d2835742286c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b8b1e4-d5b8-4509-a3fd-476942bb9e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49a19e8-00c8-444a-8f64-4feff8540dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3927cbb9-4313-4ce7-88cb-64e7bbde1187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "import openai\n",
    "import google.generativeai as palm\n",
    "\n",
    "llm_api_options = [\"OpenAI API\",\"Azure OpenAI API\",\"Google PaLM API\", \"Llama 2\"]\n",
    "TEST_MESSAGE = \"Write an introductory paragraph to explain Generative AI to the reader of this content.\"\n",
    "openai_models = [\"gpt-4\", \"gpt-4-0613\", \"gpt-4-32k\", \"gpt-4-32k-0613\", \"gpt-3.5-turbo\",\n",
    " \n",
    "                     \"gpt-3.5-turbo-0613\", \"gpt-3.5-turbo-16k\", \"gpt-3.5-turbo-16k-0613\", \"text-davinci-003\", \n",
    "                     \"text-davinci-002\", \"text-curie-001\", \"text-babbage-001\", \"text-ada-001\"]\n",
    "\n",
    "google_palm_models = [\"models/text-bison-001\", \"models/chat-bison-001\",\"models/embedding-gecko-001\"]\n",
    "\n",
    "azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_deployment_name = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "google_palm_key = os.getenv(\"GOOGLE_PALM_AI_API_KEY\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "azure_openai_api_key = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "temperature = 0.7\n",
    "\n",
    "def openai_text_completion(prompt: str, model: str):\n",
    "    try:\n",
    "        system_prompt: str = \"Explain in detail to help student understand the concept.\",\n",
    "        assistant_prompt: str = None,\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": f\"{prompt}\"},\n",
    "            {\"role\": \"system\", \"content\": f\"{system_prompt}\"},\n",
    "            {\"role\": \"assistant\", \"content\": f\"{assistant_prompt}\"}\n",
    "        ]\n",
    "        openai.api_key = openai_api_key\n",
    "        openai.api_version = '2020-11-07'\n",
    "        completion = openai.ChatCompletion.create(\n",
    "            model = model, \n",
    "            messages = messages,\n",
    "            temperature = temperature\n",
    "        )           \n",
    "        response = completion[\"choices\"][0][\"message\"].content\n",
    "        return \"\", response\n",
    "    except Exception as exception:\n",
    "        print(f\"Exception Name: {type(exception).__name__}\")\n",
    "        print(exception)\n",
    "        return f\" openai_text_completion Error - {exception}\", \"\"\n",
    "\n",
    "def azure_openai_text_completion(prompt: str, model: str):\n",
    "    try:\n",
    "        system_prompt: str = \"Explain in detail to help student understand the concept.\",\n",
    "        assistant_prompt: str = None,\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": f\"{prompt}\"},\n",
    "            {\"role\": \"system\", \"content\": f\"{system_prompt}\"},\n",
    "            {\"role\": \"assistant\", \"content\": f\"{assistant_prompt}\"}\n",
    "        ]\n",
    "        openai.api_key = azure_openai_api_key\n",
    "        openai.api_type = \"azure\"\n",
    "        openai.api_version = \"2023-05-15\" \n",
    "        openai.api_base = f\"https://{azure_endpoint}.openai.azure.com\"\n",
    "        completion = openai.ChatCompletion.create(\n",
    "            model = model, \n",
    "            engine = azure_deployment_name,\n",
    "            messages = messages,\n",
    "            temperature = temperature\n",
    "        )           \n",
    "        response = completion[\"choices\"][0][\"message\"].content\n",
    "        return \"\", response\n",
    "    except Exception as exception:\n",
    "        print(f\"Exception Name: {type(exception).__name__}\")\n",
    "        print(exception)\n",
    "        return f\" azure_openai_text_completion Error - {exception}\", \"\"\n",
    "\n",
    "\n",
    "def palm_text_completion(prompt: str, model: str):\n",
    "    try:        \n",
    "        candidate_count = 1\n",
    "        top_k = 40\n",
    "        top_p = 0.95\n",
    "        max_output_tokens = 1024\n",
    "        palm.configure(api_key=google_palm_key)\n",
    "        defaults = {\n",
    "                  'model': model,\n",
    "                  'temperature': temperature,\n",
    "                  'candidate_count': candidate_count,\n",
    "                  'top_k': top_k,\n",
    "                  'top_p': top_p,\n",
    "                  'max_output_tokens': max_output_tokens,\n",
    "                  'stop_sequences': [],\n",
    "                  'safety_settings': [{\"category\":\"HARM_CATEGORY_DEROGATORY\",\"threshold\":1},{\"category\":\"HARM_CATEGORY_TOXICITY\",\"threshold\":1},{\"category\":\"HARM_CATEGORY_VIOLENCE\",\"threshold\":2},{\"category\":\"HARM_CATEGORY_SEXUAL\",\"threshold\":2},{\"category\":\"HARM_CATEGORY_MEDICAL\",\"threshold\":2},{\"category\":\"HARM_CATEGORY_DANGEROUS\",\"threshold\":2}],\n",
    "                }\n",
    "        \n",
    "        response = palm.generate_text(\n",
    "          **defaults,\n",
    "          prompt=prompt\n",
    "        )\n",
    "        return \"\", response.result\n",
    "    except Exception as exception:\n",
    "        print(f\"Exception Name: {type(exception).__name__}\")\n",
    "        print(exception)\n",
    "        return f\" palm_text_completion Error - {exception}\", \"\"\n",
    "\n",
    "def test_handler(optionSelection, prompt: str = TEST_MESSAGE, openai_model_name: str =\"gpt-4\", google_model_name: str =\"models/text-bison-001\"):\n",
    "    match optionSelection:\n",
    "        case  \"OpenAI API\":\n",
    "            message, response = openai_text_completion(prompt,openai_model_name)\n",
    "            return message, response\n",
    "        case  \"Azure OpenAI API\":\n",
    "            message, response = azure_openai_text_completion(prompt,openai_model_name)\n",
    "            return message, response\n",
    "        case  \"Google PaLM API\":\n",
    "            message, response = palm_text_completion(prompt,google_model_name)\n",
    "            return message, response\n",
    "        case  \"Llama 2\":\n",
    "            return f\"{optionSelection} is not yet implemented!\", \"\"\n",
    "        case _:\n",
    "            if optionSelection not in llm_api_options:\n",
    "                return ValueError(\"Invalid choice!\"), \"\"\n",
    "\n",
    "        \n",
    "\n",
    "with gr.Blocks() as LLMDemoTabbedScreen:\n",
    "    with gr.Tab(\"Text-to-Text (Text Completion)\"):\n",
    "        llm_options = gr.Radio(llm_api_options, label=\"Select one\", info=\"Which service do you want to use?\", value=\"OpenAI API\")\n",
    "        with gr.Row():\n",
    "            with gr.Column(): \n",
    "                test_string = gr.Textbox(label=\"Try String\", value=TEST_MESSAGE, lines=5)\n",
    "                test_string_response = gr.Textbox(label=\"Response\",  lines=5)\n",
    "                test_string_output_info = gr.Label(value=\"Output Info\", label=\"Info\")\n",
    "                test_button = gr.Button(\"Try it\")\n",
    "    with gr.Tab(\"API Settings\"):\n",
    "        with gr.Tab(\"Open AI\"):\n",
    "            openai_model = gr.Dropdown(openai_models, value=\"gpt-4\", label=\"Model\", info=\"Select one, for Natural language\")\n",
    "        with gr.Tab(\"Google PaLM API\"):\n",
    "            google_model_name = gr.Dropdown(google_palm_models, \n",
    "                                                   value=\"models/text-bison-001\", label=\"Model\", info=\"Select one, for Natural language\") \n",
    "        \n",
    "    test_button.click(\n",
    "            fn=test_handler,\n",
    "            inputs=[llm_options, test_string, openai_model, google_model_name],\n",
    "            outputs=[test_string_output_info, test_string_response]\n",
    "    )\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    LLMDemoTabbedScreen.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db16904-706a-4b6b-9433-8c9bfa097ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
